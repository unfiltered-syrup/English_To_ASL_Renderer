{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (4.50.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from transformers) (0.30.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from requests->transformers) (2024.12.14)\n",
      "Requirement already satisfied: datasets in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (3.5.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from datasets) (4.66.5)\n",
      "Requirement already satisfied: xxhash in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from datasets) (3.10.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from datasets) (0.30.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from aiohttp->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from aiohttp->datasets) (1.11.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from huggingface-hub>=0.24.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
      "Requirement already satisfied: colorama in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: torch in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: SentencePiece in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (0.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: \"'accelerate\": Expected package name at the start of dependency specifier\n",
      "    'accelerate\n",
      "    ^\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (4.50.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from transformers[torch]) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from transformers[torch]) (0.30.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from transformers[torch]) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from transformers[torch]) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from transformers[torch]) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from transformers[torch]) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from transformers[torch]) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from transformers[torch]) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from transformers[torch]) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from transformers[torch]) (4.66.5)\n",
      "Requirement already satisfied: torch>=2.0 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from transformers[torch]) (2.6.0)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from transformers[torch]) (1.6.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from accelerate>=0.26.0->transformers[torch]) (5.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers[torch]) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers[torch]) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from torch>=2.0->transformers[torch]) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from torch>=2.0->transformers[torch]) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from torch>=2.0->transformers[torch]) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from torch>=2.0->transformers[torch]) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from sympy==1.13.1->torch>=2.0->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from requests->transformers[torch]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from requests->transformers[torch]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from requests->transformers[torch]) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from requests->transformers[torch]) (2024.12.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from jinja2->torch>=2.0->transformers[torch]) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install datasets\n",
    "!pip install torch\n",
    "!pip install SentencePiece\n",
    "!pip install 'accelerate>=0.26.0'\n",
    "!pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "\n",
    "# Load text files\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower().strip()  # Lowercase and strip spaces\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)  # Remove punctuation\n",
    "    return text\n",
    "\n",
    "def load_text(filename):\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as file:\n",
    "        return [clean_text(line) for line in file.read().splitlines() if line.strip()]\n",
    "\n",
    "# Load data\n",
    "en_sentences = load_text(\"en.txt\")\n",
    "gloss_sentences = load_text(\"gloss.txt\")\n",
    "en_sentences = [line.strip() for line in en_sentences if line.strip()]\n",
    "gloss_sentences = [line.strip() for line in gloss_sentences if line.strip()]\n",
    "# Use T5 tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a56d8ba11dc4f3daa859847511b62ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare dataset with task prefix\n",
    "def tokenize_function(examples):\n",
    "    inputs = [\"translate English to Gloss: \" + sentence for sentence in examples[\"en\"]]\n",
    "    targets = examples[\"gloss\"]\n",
    "    \n",
    "    model_inputs = tokenizer(inputs, padding=True, truncation=True, max_length=128)\n",
    "    labels = tokenizer(targets, padding=True, truncation=True, max_length=128)\n",
    "    \n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "print(len(en_sentences), len(gloss_sentences))\n",
    "# Create dataset\n",
    "data = Dataset.from_dict({\"en\": en_sentences, \"gloss\": gloss_sentences})\n",
    "tokenized_datasets = data.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniel Chu\\anaconda\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\Daniel Chu\\AppData\\Local\\Temp\\ipykernel_23644\\2450524126.py:17: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='35' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 05:16, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>9.806201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>9.029267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>8.441807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>8.036497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>7.893742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('english_to_gloss_t5\\\\tokenizer_config.json',\n",
       " 'english_to_gloss_t5\\\\special_tokens_map.json',\n",
       " 'english_to_gloss_t5\\\\spiece.model',\n",
       " 'english_to_gloss_t5\\\\added_tokens.json')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model (T5 for translation)\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets,\n",
    "    eval_dataset=tokenized_datasets,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# Train model\n",
    "trainer.train()\n",
    "\n",
    "# Save model\n",
    "model.save_pretrained(\"english_to_gloss_t5\")\n",
    "tokenizer.save_pretrained(\"english_to_gloss_t5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_en_sentences = load_text(\"test_en.txt\")\n",
    "test_gloss_sentences = load_text(\"test_gloss.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sacrebleu in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: portalocker in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from sacrebleu) (3.1.1)\n",
      "Requirement already satisfied: regex in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from sacrebleu) (2024.9.11)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from sacrebleu) (1.26.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from sacrebleu) (0.4.6)\n",
      "Requirement already satisfied: lxml in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from sacrebleu) (5.2.1)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\daniel chu\\anaconda\\lib\\site-packages (from portalocker->sacrebleu) (305.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install sacrebleu\n",
    "import sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'eval_loss': 7.893741607666016, 'eval_runtime': 14.2882, 'eval_samples_per_second': 6.999, 'eval_steps_per_second': 0.49, 'epoch': 5.0}\n",
      "reference: [['now condition'], ['alack for pitty pro1 not remembringwhqhowpro1 cride out then will cry pro3it ore againe pro3itbea hint that wrings mine eyes too t'], ['heare little further and then pro1 le bring thee to present businesse which now vpon without which this storybemost impertinent'], ['wherefore did pro3they not that howre destroy vs'], ['well demanded wench poss1 tale prouokes that question deare pro3they durst not so deare loue poss1 people bore pro1me nor set marke so bloudy on businesse but with colours fairer painted poss3they foule ends']] prediction:  ['jetzt die Lage', 'ich schreie es ere es ist ein Hinweis,', '', 'Darum zerstörten sie nicht diesen Thron', 'es hat mir erfordert, daß ich es er']\n",
      "BLEU Score on Test Set: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "eval_results = trainer.evaluate()\n",
    "print(\"Evaluation Results:\", eval_results)\n",
    "\n",
    "# BLEU Score Evaluation\n",
    "def compute_bleu(model, tokenizer, dataset):\n",
    "    references = []\n",
    "    predictions = []\n",
    "    \n",
    "    for example in dataset:\n",
    "        input_text = \"translate English to Gloss: \" + example[\"en\"]\n",
    "        input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "        output_ids = model.generate(input_ids)\n",
    "        prediction = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "        \n",
    "        references.append([example[\"gloss\"]])\n",
    "        predictions.append(prediction)\n",
    "    print ('reference:', references[:5], 'prediction: ', predictions[:5])\n",
    "    bleu = sacrebleu.corpus_bleu(predictions, references)\n",
    "    return bleu.score\n",
    "\n",
    "# Create test dataset\n",
    "test_data = Dataset.from_dict({\"en\": test_en_sentences, \"gloss\": test_gloss_sentences})\n",
    "bleu_score = compute_bleu(model, tokenizer, test_data)\n",
    "print(\"BLEU Score on Test Set:\", bleu_score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
